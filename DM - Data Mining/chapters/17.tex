\chapter{Time Series}

// TODO intro to time series is missing

\section{Classification}

Given a set $X$ of $n$ time series, $X = {x_1, x_2, \dots, x_n}$, each time series has m ordered values $x_i = \langle x_{t1}, x_{t2}, \dots, x_tm \rangle$ and a class value $c_i$.

The objective is to find a function $f$ that maps from the space of possible time series to the space of possible class values.

Generally, it is assumed that all the TS have the same length m.

\subsection{Shapelet-based classification}
\begin{paracol}{2}
   
   \begin{definition}
      [Shapelet-based classification]
   
      First represent a TS as a vector of distances with representative subsequences, namely \textbf{shapelets}.
      Then, use it as input for machine
      learning classifiers.
   
   \end{definition}

   \switchcolumn

   \begin{figure}[htbp]
      \centering
      \includegraphics{images/17/shapelet0.png}
      % \caption{}
      \label{fig:17/shapelet0}
   \end{figure}
\end{paracol}


\begin{figure}[htbp]
   \centering
   \includegraphics{images/17/shapelet1.png}
   \caption{Shapelet application example}
   \label{fig:17/shapelet1}
\end{figure}


When it comes to time series, \ul{\textbf{shapelets} are \textit{TS subsequences} which are
maximally representative} of a class.\\
Shapelets can provide interpretable results,which may help domain practitioners betterunderstand their data.\\
Furthermore, shapelets can be significantly more accurate/robust because they are local features, whereas most other state-of-the-art TS classifiers consider global features.

% Finding shapelets


% finding candidates


\begin{algorithm}
\caption{GenerateCandidates(\textbf{dataset} $D$, $MAXLEN$, $MINLEN$)}
\begin{algorithmic}[1]
   \State $pool \gets \varnothing$
   \State $l \gets MAXLEN$
   \While{$l \ge MINLEN$}
      \For{each time series $T$ in $D$}
         \State $pool \gets pool \cup S_T^{l}$ \Comment{add all subsequences of length $l$ from $T$}
      \EndFor
      \State $l \gets l - 1$
   \EndWhile
   \State \Return $pool$
\end{algorithmic}
\label{alg:generatecandidates}
\end{algorithm}

\begin{algorithm}
\caption{FindingShapeletBF(\textbf{dataset} $D$, $MAXLEN$, $MINLEN$)}
\begin{algorithmic}[1]
   \State $candidates \gets \text{GenerateCandidates}(D, MAXLEN, MINLEN)$
   \State $bsf\_gain \gets 0$
   \State $bsf\_shapelet \gets \text{null}$
   \For{each shapelet $S$ in $candidates$}
      \State $gain \gets \text{CheckCandidate}(D, S)$
      \If{$gain > bsf\_gain$}
         \State $bsf\_gain \gets gain$
         \State $bsf\_shapelet \gets S$
      \EndIf
   \EndFor
   \State \Return $bsf\_shapelet$
\end{algorithmic}
\label{alg:findingshapeletbf}
\end{algorithm}

\begin{algorithm}
\caption{CalculateInformationGain(\textbf{distance histogram} $obj\_hist$)}
\begin{algorithmic}[1]
   \State $split\_dist \gets \text{OptimalSplitPoint}(obj\_hist)$
   \State $D_1 \gets \varnothing,\quad D_2 \gets \varnothing$
   \For{each entry $d$ in $obj\_hist$}
      \If{$d.dist \le split\_dist$}
         \State $D_1 \gets D_1 \cup d.objects$
      \Else
         \State $D_2 \gets D_2 \cup d.objects$
      \EndIf
   \EndFor
   \State \Return $I(D) - \hat{I}(D)$ \Comment{return information gain after split}
\end{algorithmic}
\label{alg:calculateinformationgain}
\end{algorithm}

% check candidates


Distance from the TS to the subsequence SubsequenceDist(T, S) is a distance
function that takes time series T and subsequence S as inputs and returns a non-
negative value d, which is the distance from T to S.

% Algorithms from slides: CheckCandidate, GenerateCandidates


\begin{algorithm}
\caption{CheckCandidateDetailed(\textbf{dataset} $D$, \textbf{shapelet candidate} $S$)}
\begin{algorithmic}[1]
   \State $objects\_histogram \gets \varnothing$
   \For{each $T$ in $D$}
      \State $dist \gets \text{SubsequenceDist}(T, S)$
      \State // group objects by the distance value
      \State insert $T$ into $objects\_histogram$ by the key $dist$
   \EndFor
   \State \Return $\text{CalculateInformationGain}(objects\_histogram)$
\end{algorithmic}
\label{alg:checkcandidate-detailed}
\end{algorithm}


// TODO up to slide 23

\section{Motif}

\textbf{Motif} discovery essentially is finding repeated patterns, i.e., pattern mining. That is
\coolquote{
   Are there any repeated patterns, of length m in the TS?
}{}
\begin{figure}[htbp]
   \centering
   \includegraphics{images/17/motif0.png}
   \caption{Repeated patterns example}
   \label{fig:17/motif0}
\end{figure}


There are several reasons why motif discovery is useful:
\begin{itemize}
	\item Mining \textbf{association rules} in TS requires the discovery of motifs. These are referred to as \textit{primitive shapes} and \textit{frequent patterns}.
	\item Several \textbf{TS classifiers} work by constructing typical \textit{prototypes} of each class. These prototypes may be considered motifs.
	\item Many \textbf{TS anomaly detection} algorithms consist of modeling \textit{normal behavior} with a set of typical shapes (which we see as motifs), and detecting future patterns that are dissimilar to all typical shapes.
\end{itemize}

\subsection{Algorithm}

The Matrix Profile (MP) is a data structure that annotates a TS and
can be exploited for many purposes, e.g. efficient Motif Discovery.

Given a time series, T and a desired subsequence length, $m$.

Note that $m$ is \ul{fixed and decided apriori}. 
The algorithm may be applied multiple times with multiple $m$ values to find the best motifs.


\begin{figure}[htbp]
   \centering
   \includegraphics{images/17/matrixProfile.png}
   \caption{Finding subsequences of length $m$, along with distance matrix}
   \label{fig:17/matrixProfile}
\end{figure}

\begin{paracol}{2}
   
   For each subsequence we keep only the distance with the closest \textbf{nearest neighbor}.
   The \textbf{distance} to the corresponding nearest neighbor of each subsequence can be stored in a vector called \textbf{matrix profile} $P$.\\
   The matrix profile value at location $i$ is the distance between $T_i$ and its nearest neighbor

   \switchcolumn

   \begin{figure}[htbp]
      \centering
      \includegraphics{images/17/matrixNeighbors.png}
      \caption{Finding the closest neighbor for each pattern}
      \label{fig:17/matrixNeighbors}
   \end{figure}

\end{paracol}


\begin{figure}[htbp]
   \centering
   \includegraphics{images/17/matrixProfileIndex.png}
   \caption{Matrix profile \textbf{index}}
   \label{fig:17/matrixProfileIndex}
   The index of corresponding nearest neighbor of each
   subsequence is also stored in a vector called matrix profile
   index.
\end{figure}


The MP index allows to find the nearest neighbor to any subsequence in constant
time.\\
Note that the pointers in the matrix profile index are not necessarily symmetric.
If A points to B, then B \textit{may or may not} point to A.

The classic TS motif: the two smallest values in the MP must have the same value,
and their pointers must be mutual.

\begin{figure}[htbp]
   \centering
   \includegraphics{images/17/matrixProfile1.png}
   \caption{Matrix Profile and what its index represents}
   \label{fig:17/matrixProfile1}
\end{figure}

\subsection{Reading the Matrix Profile}
\begin{itemize}
	\item For relatively low values, you know that the subsequence in the original TS must have (at least one) relatively similar subsequence elsewhere in the data (such regions are “motifs”)
	\item For relatively high values, you know that the subsequence in the original TS must be unique in its shape (such areas are anomalies).
\end{itemize}

\begin{figure}[htbp]
   \centering
   \includegraphics{images/17/readingMP.png}
   \caption{Reading the matrix profile}
   \label{fig:17/readingMP}
\end{figure}


\subsection{Computing the Matrix Profile}

% // TODO computing the matrix profile





