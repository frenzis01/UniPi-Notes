\chapter{Replication}

\begin{definition}
   [Replication]
   Replication is the process of sharing information so as to ensure consistency between redundant resources, such as software or hardware components, to improve reliability, fault-tolerance, or accessibility.

\end{definition}


% // TODO up to leaders and followers

\section{Replication Fashions}
Each node may store a copy of the database, in this case it is called a \textbf{replica}, so, ensuring consistency among replicas is crucial.


\subsection{Leaders and followers}

\subsection{Synchronous vs Asynchronous Replication}
\begin{itemize}
   \item \textbf{Synchronous} - The leader waits for the followers to acknowledge the write before acknowledging the write itself.
   \begin{itemize}
      \item Ensures that followers have an up-to-date copy of the data.
      \item The disadvantage is that the system may become unavailable if a follower is slow to respond.
   \end{itemize}
   \item \textbf{Asynchronous} - The leader does not wait for the followers to acknowledge the write before acknowledging the write itself.
   \begin{itemize}
      \item Follower may fall behind the leader.
      \item The advantage is that the system continues processing even if a follower is slow to respond.
   \end{itemize}
   \item \textbf{Semi-synchronous} - The leader waits for a quorum of followers (at least one follower, typically always the same and placed in another location) to acknowledge the write before acknowledging the write itself.
   \begin{itemize}
      \item Ensures that at least one follower has an up-to-date copy of the data.
      \item Typically there is \ul{only one node fully synchronous}, while others are asynchronous, and it is \ul{placed far away from the leader}.
   \end{itemize}
\end{itemize}

\section{Failure}
\begin{itemize}
   \item Node failures - Nodes can fail due to faults or planned maintenance. The goal is to minimize impact and keep the system running.
   \item Follower failure: Catch up recovery - Followers keep a log of data Challenges //TODO
   % // TODO
   \item Leader failure: Failover - 
   \item Challenges in Failover -
\end{itemize}

\subsection{Implementing Replication Logs}
\begin{itemize}
   \item \textbf{Statement-based} replication - Replicate SQL write requests statements from the leader to the followers.
   \note{We cannot ensure a fully consistent system, due to issues with non-deterministic functions, autoincrementing columns, and side effects.\\
   This was used in VoltDB and MySQL before version 5.1.}
   \item \textbf{Write-ahead log (WAL)} shipping - Replicate the log of changes to the database from the leader to the followers.
   \note{Still some problems here, because we assume that the leader and the followers are using the same database engine, same architecture an so on, so that the log is the same.}
   \item \textbf{Logical log} replication - Replicate a logical representation of changes to the database from the leader to the followers.
   \note{This is advantageous and flexible, but it is dischouraged by the fact that some expertise and coding are required. Instead, with the first two approaches there is no need to modify the database in any way.}
   \item \textbf{Trigger-based} replication - Replicate changes to the database by using triggers.
\end{itemize}


\section{Eventual Consistency}
The eventual consistency model implies a temporary state where the followers lag behind the leader, but eventually they will catch up. 
Hence there is some ``replication-lag'' \dots
% //TODO

\subsection{Read-after-write consistency}
In asynchronous replication it is not trivial to ensure \textit{read-your-write} consistency, i.e. if a client writes a value to the leader, it should be able to read it.
In other words, a user may think their data is lost, because they cannot see it, but it is actually there, just not yet replicated to the follower.

\textit{Read-after-write} consistency guarantees that \ul{users see their own updates, but not necessarily the updates of others.}
It may be implemented by reading user-modified data from the leader.

\subsection{Monotonic Reads}
\textit{Monotonic reads} consistency guarantees that if a user has read the value of a key, it will not read an older value of the same key in the future.
It is stronger than eventual consistency, but weaker than strong consistency.

In asynchronous replication may see data moving backward in time when reading from different replicas with varying lag.\\
Monotonic reads can be achieved by ensuring that reads are always performed on the same replica.

\subsection{Consistent Prefix Reads w/different DBs}
\textit{Consistent prefix reads} consistency guarantees that if a sequence of writes happens in a certain order, then a read will see those writes in the same order.

Suppose that $A$ asks $B$ something, and $C$ is listening, but hears first the answers and later the question: weird, ain't it?\\
This may happen due to replication lag. We want to prevent casuality violations.


\section{Multi-Leader Replication}
With a single-leader configuration, the leader is a bottleneck, and if it fails, the system elects a new leader (perhaps there may be a small downtime).

With multi-leader replication, there are multiple leaders, and each leader can accept writes. This is useful for geographically distributed systems, where each region has its own leader.

\subsection{Collaborative Editing}
Real-time collaborative editing is a use case for multi-leader replication.\\
Changes are instantly appied to the user's local replica and then asynchronously replicated to the server and other users.

Application must obtain a lock on the document before editing, as with single leader replication with transactions (?).\\
The unit of change may be small, as a single keystroke.\nl

When two users edit the same part of the document, they get local updates, but when the system asynchronously synchronizes the replicas, a conflict occurs and needs resolution.\\
With single-leader replication, the second writer blocks or aborts if first write is incomplete, having the user to retry the input.\\
With multi-leader replication, the system must resolve the conflict, and the user must be notified of the resolution.

\subsection{Conflict Avoidance}
\labelitemize{Strategies}{
   \begin{itemize}
      \item Routing writes towards the same leader prevents conflicts.
      \item Routing user requests towards the same datacenter
      \item // TODO
   \end{itemize}
}

% // Prof SKIPPING a few slides starting from "consistent and converging to a state"


% // TODO
\subsection{Topologies}
\begin{itemize}
   \item \textbf{Circular} - each node receives writes and forwards writes
   \item \textbf{Star topology} - root node forwards writes to all other nodes 
   \item \textbf{All-to-all} - every leader sends writes to every other leader
\end{itemize}

Note that this is not hardware (neither virtual) network, but a logical network of replication, made up by how we manage the information flow.

In whatever topology it is important to \textbf{monitor staleness}, which is monitoring obsolete replicas, i.e. how far behind a follower is from the leader.