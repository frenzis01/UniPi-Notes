\chapter{Data Processing}

Data may be processed in either \textbf{batch} or \textbf{real-time} (\textit{stream}) fashion, or a combination of both. Batch processing is used when data can be collected and processed in a single operation, while real-time processing is used when data must be processed as soon as it is generated.

\section{Batch Processing}
This approaches relaxes the need for producing results as soon as data arrives, storing it in a buffer to later process it in chunks.

Batch processing is typically cheaper and easier to implement than real-time processing, but it may not be suitable for all use cases, but is very effective for data transformations, generate reports, and other tasks that do not require immediate results.

We have high latency, but also high throughput, and the system is easier to reason about, however, it lacks the ability for real-time decision making.

% // TODO

\section{Stream Processing}

Here the focus is on processing data as soon as it is generated.

\subsection{Time semantics}
\begin{itemize}
   \item \textit{Event} time - the time when the event occurred.
   \item \textit{Processing} time - the time when the event is processed. 
   \item \textit{Ingestion} time - the time when the event was received. 
\end{itemize}

Watermarks are used to track the progress of event time, and to determine when to emit results. In general allow for managing late-arrive data

% // TODO

Time-based windowing is used to group events into windows based on time, and to process them in parallel. Windows can be fixed or sliding, and can be based on event time or processing time.

\subsection{Lambda architectures}

A lambda architecture is a data processing architecture designed to handle massive quantities of data by taking advantage of both batch and stream processing methods. 
{It consists of three layers:\ns
%  the batch layer, the speed layer, and the serving layer.
\begin{itemize}
   \item The \textbf{batch layer} is responsible for processing large volumes of data in a fault-tolerant and scalable manner. It is used to generate views of the data that can be queried by the serving layer.
   \item The \textbf{speed layer} is responsible for processing real-time data in a low-latency manner. It is used to generate real-time views of the data that can be queried by the serving layer.
   \item The \textbf{serving layer} is responsible for serving queries on the views generated by the batch and speed layers. It is used to provide real-time access to the data to the end-users through APIs and various tools.
\end{itemize}
}


% // TODO 
\subsection{Kappa architectures}
Well suited for processing data from IoT devices.

A kappa architecture is a data processing architecture designed to handle massive quantities of data by taking advantage of stream processing methods. It consists of a single layer that processes both batch and real-time data in a fault-tolerant and scalable manner.

It is still more complex than traditional stream processing techniques, but it is more efficient and scalable.


\subsection{CQRS}
What happens if i have many writes and few reads?

Command Query Responsibility Segregation is a design pattern that separates the read and write operations of a system into two separate components. This allows for better scalability, performance, and maintainability of the system.

This looks good on the paper, but it is not always easy to implement, and may lead to inconsistencies between the read and write models.

\subsection{Data Lakehouse}

This is a modern data architecture that combines the best features of data lakes and data warehouses. It allows for the storage of raw data in a data lake, and the processing of that data in a data warehouse.

This architecture provides unified approach for structured, unstructured, and semi-structured data, and allows for the use of both batch and real-time processing methods.

An example is Snowflake, which is a cloud-based data warehouse that supports both batch and real-time processing methods.

\subsection{Federated Learning}

With federated learning, the model is trained on the edge devices, and the updates are sent to a central server. This allows for better privacy and security, as the data never leaves the edge devices.

This approach is well suited for IoT devices, as it allows for the training of models on the edge devices, and the updates are sent to a central server for aggregation.

\subsection{Serverless Data Processing}
Abstracts infrastrcture management, and allows for the deployment of data processing pipelines without the need to manage servers.