\chapter{Transactions}

Everything may fail at any time in a distributed system.
Nodes may crash, networks may partition, messages may be lost or duplicated, clients may disconnect unexpectedly, race conditions may occur\dots
In this scenario, it is crucial to maintain data consistency across multiple nodes.
\ul{Transactions provide a framework for maintaining data consistency in the presence of failures.}

\begin{definition}
   [Transaction]
   A \textbf{transaction} is a sequence of operations that are executed as a single unit of work. A transaction can consist of multiple operations, such as reads, writes, and updates.
   A transaction has to be \textbf{atomic}: all the operations in the transaction are executed successfully or none of them are.\\
   Besides, when a transaction is executed on some data, none of the other transactions can alter that data until the transaction is completed.
\end{definition}

Transactions are clearly crucial in a distributed system, as they build a framework for allowing to maintain data consistency across multiple nodes.

Transactions come at a cost, since in a distributed system even a simple mechanism such as a mutex may become costly to implement.\\
Transactions hence provide all-or-nothing guarantees, simplifying \textbf{error handling}, since partial failures are not to be managed.


\section{Deeper into DBs}

Most SQL DBs support transactions.
NoSQL databases typically do not support transactions, but some of them provide limited support for transactions on a single object.
\subsection{Why NoSQL DBs do not support transactions?}
NoSQL databases typically do not support transactions because they are designed to be highly scalable and distributed,
and transactions can be difficult to implement in a distributed system.
Transactions require coordination between multiple nodes, which can be costly and can lead to performance issues.

NoSQL databases typically prioritize scalability and performance over strong consistency guarantees, which are provided by transactions.
However, some NoSQL databases provide limited support for transactions on a single object, which can be useful for certain applications.



\section{ACID Properties}

\begin{itemize}
    \item \textbf{Atomicity}: all operations in a transaction are executed successfully or none of them are.
    \item \textbf{Consistency}: the database is in a consistent state before and after the transaction.
    \item \textbf{Isolation}: the transaction is executed in isolation from other transactions.
    \note{In other words, transactions appear to run serially}
    \item \textbf{Durability}: once a transaction is committed, the changes are permanent.
    \note{Perfect durability is unattainable}
\end{itemize}

These were coined by \textit{Jim Gray} in 1983.

\subsection{Atomicity}
Ensures no other thread can see a half-finished operation. System is either in the state before or after the operation.
It is not about concurrency, but about handling faults during transactions. Ensures all writes in a transaction are discarded if a fault occurs.
Prevents partial changes and ensures data integrity.

\subsection{Consistency}
Involves statements about data (\textit{invariants}) that must always be true. 
\note{Example: In accounting, credits and debits must always balance}
Application must define transactions correctly to preserve consistency: database cannot guarantee consistency if application writes bad data.

Database can check specific invariants using constraints, but these are application specific.
Atomicity, isolation, and durability are \textit{database properties}, but \textbf{Consistency}, instead, is an \textit{application property} relying on atomicity and isolation.

\subsection{Isolation}
Multiple clients accessing the same records can cause race conditions.
Isolation ensures transactions are isolated from each other, thus they appear to run serially.
In fact it is formalized as serializability.

\subsection{Durability}
Durability is the property that ensures that once a transaction is committed, the changes are permanent.

This is a mess to ensure and in general is not possible to guarantee, but it is possible to make it very unlikely that a transaction is lost.

The issue is related to hardware faults, power outages, broken firmware,\dots\\
Given the absence of a one-size-fits-all solution, typically the approach involves a combination of writing to disk, replicating to remote machines, and backups.

\subsection{Single-Object and Multi-Object Transactions}
If a \ul{transaction involves multiple objects, it is a multi-object transaction, which causes \textbf{performance} and \textbf{deadlock} issues.}
Multi-object transactions require some way of determining which read and write operations belong to which transaction.

Single-object operations prevent lost updates when multiple clients write concurrently.
These operations are not traditional transactions, since they do not provide atomicity across multiple objects.
Terms like ``lightweight transactions'' or ``ACID for single objects'' can be misleading.
\nl

Transactions require aborting and rolling back changes if something goes wrong. Note however that retrying after permanent errors (e.g., constraint violations), or overload-related errors is pointless.
It is also important to manage side effects, such as sending emails or updating caches, which may not be rolled back and must be performed only once the transaction is committed.

\section{Avoiding Transactions}
Transactions can safely run in parallel if they do not modify the same data. Concurrency issues arise when two transactions modify the same data simultaneously.\\
Race conditions can occur when one transaction reads data that is concurrently modified by another transaction.

Databases hide concurrency issues by providing transaction isolation.
Isolation allows the application to pretend that no concurrency is happening.
\ul{Serializable isolation guarantees that the transactions are executed in a serial order, which is the most strict isolation level.}

Serializable isolation comes with a performance cost which makes it less common in practice.
Weaker isolation levels are common, but are harder to understand and may lead to subtle bugs.

\subsection{Read Committed}
In \textit{Read Committed} isolation level, a transaction can only read, and overwrite, committed data.
This is the default isolation level in most databases.
Databases prevent dirty reads using an approach that stores both the old committed value and the new value set by the current transaction.

\begin{definition}
   [Dirty Read]
   A \textbf{dirty read} occurs when a transaction reads data that has been written by another transaction that has not yet been committed.
\end{definition}


\begin{definition}
   [Dirty Write]
   A \textbf{dirty write} occurs when a transaction overwrites data that has been written by another transaction that has not yet been committed.
\end{definition}

In this model, \ul{\textbf{no} dirty reads nor dirty writes are allowed}.

% This model is not enough to prevent \textbf{non-repeatable reads} and \textbf{phantom reads}.
This model is more reliable than Non-transactional models, but still allows to avoid ``paying'' for transactions.

\begin{definition}
   [Non-repeatable Read]
   A \textbf{non-repeatable read} occurs when a transaction reads the same data twice and gets different results.\\
   This is also called \textbf{read skew}.
\end{definition}

Non-repeatable reads are possible in \textit{Read Committed} isolation level, 

\begin{figure}[htbp]
   \centering
   \includegraphics{images/12/readcommitted_issue.png}
   \caption{Read committed issue: Alice might think that her whole balance is 900, whilst it is 1000.}
   \label{fig:12/readcommitted_issue}
\end{figure}
% \begin{definition}
%    [Phantom Read]
%    A \textbf{phantom read} occurs when a transaction reads a set of records that satisfy a certain condition, but when it reads the same records again, the set of records has changed.

\subsection{Snapshot Isolation}
\textit{Snapshot Isolation} is a more relaxed isolation level than serializable isolation, but it is still stricter than \textit{Read Committed} isolation.

In \textit{Snapshot Isolation}, a transaction reads a snapshot of the database at the beginning of the transaction and writes to the database at the end of the transaction.

The snapshot allows transactions to see all the data that was commited at the start of the transaction.


\note{It is possible to use some techniques for locking the database, using locks or atomic operations. 
However it is costful}

This model implements isolation by means of a lock to prevent dirty writes, but allows dirty reads (?), since reads do not acquire any locks.
Readers never block writers, and writers never block readers.\\
Along with locks, MVCC (Multi-Version Concurrency Control) is used to provide each transaction with a snapshot of the database at the start of the transaction.
In practice, each write creates a new version of the object, and the old version is kept around for readers that started before the write.

Compared to \textit{Read Committed}, we could say that while \textit{Read Committed} uses a \ul{separate snapshot for each \textbf{query}}, \textit{Snapshot Isolation} uses a \ul{single snapshot for the whole \textbf{transaction}}.

\section{Write Skew and Phantoms}
There may happen write-write conflicts, causing \textbf{lost updates}. They occur during read-modify-write cycles, when two transactions read the same data, then update ---possibly separate--- objects based on the read data, and then commit, causing a conflict.

A key solution is to eliminate the read-modify-write cycle by using atomic operations.
When these are insufficient, it is possible to use explicit locks to prevent concurrent access to the data.\\
Alternatively, the DB could also detect lost updates and in case abort one of the transactions.


\begin{paracol}{2}
  
   \colfill
   \begin{definition}
      [Write Skew]
      A \textbf{write skew} occurs when two transactions read the same data, then update ---possibly separate--- objects based on the read data, and then commit, causing a conflict.
   \end{definition}
   There are some techniques to avoid write skew, such as using row locks, atomic operations, or specific constraints, but we did not discuss them pretty much.
   \colfill
   
   \switchcolumn

   \begin{figure}[htbp]
      \centering
      \includegraphics[width=0.9\columnwidth]{images/12/write_skew.png}
      \caption{Both doctors read that \lstinline|currently_on_call >= 2| and ``leave the hospital'', causing no doctor to be on call \frownie.}
      \label{fig:12/write_skew}
   \end{figure}
\end{paracol}



