\chapter{JVM Instr Set \& JIT}
\section{Instruction Set}
% \section*{26 - Settembre}


Let's consider the instructions \textbf{format} of the JVM.
Each instruction may have different \textit{``forms''} supporting different kinds of operands.
For example there are different forms of \lst{iload} (i.e. push).
\note{\begin{itemize}
    \item \lst{iload_0} pushes the first local variable
    \item \lst{iload_1} pushes the second local variable
    \item \lst{iload_2} pushes the third local variable
    \item \dots
\end{itemize}}

{Runtime memory contains\ns
\begin{itemize}
	\item Local variable array (frame)
	\item Operand stack (frame)
	\item Object fields (heap)
	\item Static fields (method area)
\end{itemize}}

Note that Java instructions are explicitly typed through \textbf{opCodes}, e.g. \lst{dload},\lst{iload},\lst{fload}.\\
\textbf{opCodes} are bytes, allowing only for 256 distinct ones;
hence it is impossible to have for each instruction one opCode per type.
The JVM specification indicates a selection of which types to support for each op instruction, and not supported types have to be converted; resulting in the Instruction Set Architecture to present non-orthogonality.\\
Types like \lst{byte}, \lst{char} and \lst{short} are usually converted to \lst{int} when performing computations.

% \section*{27 - Settembre}

\subsection{Invoking methods}
\lst{invokevirtual} causes the allocation of a new frame, pops the arguments from the stack into the local variables of the caller (putting this in 0),
and passes the control to it by changing the \lst{pc}.
\begin{itemize}
    \item A resolution of the symbolic link is performed
    \item \lst{ireturn} pushes the top of the current stack to the stack of the caller, and passes the control to it. Similarly for \lst{dreturn}, \lst{freturn} ...
    \item \lst{return} just passes the control to the caller
\end{itemize}

{There are 4 others kinds of method invocation:\ns
\begin{itemize}
    \item \lst{invokestatic}: call methods with \lst{static} modifier; \textit{this} is not passed
    \item \lst{invokespecial}: call constructors, \lst{private} methods or \textit{superclass} methods; \textit{this} is always passed 
    \item \lst{invokeinterface}: identical to \lst{invokevirtual}, but used when the method is declared in an interface, thus a different lookup is required
    \item \lst{invokedynamic}: introduced in Java 7 to support dynamic typing\footnote{lambda functions related?}
\end{itemize}}
\note{In the slides (``JVM Instruction Set'') there are many examples on how code snippets are translated into bytecode.}

\section{JIT}
\textit{AOT} \textbf{Ahead of Time} \textit{Compilation} leads to better performance in general, exploiting hardware features and variables allocation without runtime lookup;
While \textbf{Interpretation} facilitates interactive debugging and testing: it allows command-line invocation.

\textbf{JIT} aims to get the advantages of both.

\textit{JIT} differs from \textit{AOT} since it runs in the same process of the application and competes with the app for resources,
thus compilation time for JIT is more relevant than for an AOT Compiler.
Besides, a JIT compiler doesn't verify classes at compile time, it is a task performed by the JVM at load time. 
JIT can exploit new optimization possibilities, e.g. \textit{deoptimization} and \textit{speculation}.
A JIT takes bytecode as input and outputs machine code that the CPU executes directly.\\
{Wrapping up:\ns
\begin{itemize}
    \item Code \ul{starts executing interpreted with no delay}
    \item Methods that are found commonly executed (\textit{hot}) are JIT compiled
    \item Once compiled code is available, the execution switches to it.
\end{itemize}
}
To identify \textit{hot} methods, there is a \textbf{threshold} on two \textit{per-method} counters:
\begin{enumerate}
    \item Times the method is invoked
    \item Times a branch back to the start of a loop is taken in the method
\end{enumerate}

JIT aims for a tradeoff between "fast-to-start-but-slow-to-execute" interpreter vs "slow-to- start-but-fast-to-execute" compiled code, which may be efficiently implemented by a \textbf{multi tier system}, consisting of \textit{interpreter}, \textit{quick compiler}, and \textit{optimizing compiler.}

\begin{itemize}
	\item Java code starts execution in the interpreter.
	\item When a method becomes warm ($threshold: \approx 1.500$), it's
enqueued for compilation by the quick compiler.
	\item Execution switches to that compiled code when it's ready.
	\item Method executing in the second tier is still instrumented:
when it becomes hot ($threshold: \approx 10.000$), then it's
enqueued for compilation by the optimizing compiler.
	\item Execution continues in the second-tier compiled code until
the faster code is available.
\end{itemize}

\subsection{Deoptimization and Speculation}
Usually method executions pass in three phases:
\nl

\begin{tikzpicture}
    \node[shape=rectangle,draw=white] (A) at (0,0) {Interpreter};
    \node[shape=rectangle,draw=white] (B) at (3,0) {Low tier compiler};
    \node[shape=rectangle,draw=white] (C) at (7,0) {Optimizing compiter};
    \path [->] (A) edge node[left] {} (B);
    \path [->] (B) edge node[left] {} (C);
    % \path [->] (C) edge node[left] {} (B);    
\end{tikzpicture}

But sometimes \textbf{deoptimization} can happen, i.e. :
\nl

\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=2.8cm]
    \node[shape=rectangle,draw=white] (A) at (0,0) {Interpreter};
    \node[shape=rectangle,draw=white] (B) at (3,0) {Low tier compiler};
    \node[shape=rectangle,draw=white] (C) at (7,0) {Optimizing compiter};

    \path [->] (A) edge node[left] {} (B);
    \path [->] (B) edge node[left] {} (C);
    \path [->] (B) edge [bend left] node {} (A);
    \path [->] (C) edge [bend left] node {} (A);
\end{tikzpicture}

{There are Two main possible causes for deoptimization:\ns
\begin{itemize}
	\item Corner cases in code
	\item \textit{Speculation}: the compiler makes some assumption to generate better (faster) code, but if an assumption is invalidated, then the thread that executes a method that
    makes such assumption, \textit{}deoptimizes in order to not execute code that's
    erroneous (being based on wrong assumptions).
\end{itemize}}

Note that deoptimization is only possible at
locations known as \textbf{safepoints}; 
the JVM has to be able to reconstruct the state of execution so the interpreter can resume the thread where the compiled execution stopped.